{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe4f179",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############\n",
    "### Imports ###\n",
    "###############\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from math import pi\n",
    "from zipfile import ZipFile\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import HalvingRandomSearchCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7414dc29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### Functions ###\n",
    "#################\n",
    "\n",
    "###############################\n",
    "### File Manipulation Funcs ###\n",
    "###############################\n",
    "\n",
    "# File listing function\n",
    "def zlist_files(data_path, zipname, cond):\n",
    "    zipped_files = join(data_path, zipname)\n",
    "    with ZipFile(zipped_files) as z:\n",
    "        flist = [f for f in z.namelist() if cond in f]\n",
    "        fout = [z.open(f) for f in flist]\n",
    "        return fout\n",
    "\n",
    "# File listing function\n",
    "def list_files(data_path, cond):\n",
    "    flist = [f for f in listdir(data_path) if isfile(join(data_path, f))]\n",
    "    fcond = [join(data_path, f) for f in flist if cond in f]\n",
    "    return fcond\n",
    "\n",
    "# Create pandas data loader for multi-json loads\n",
    "def pandas_loader(flist, idx_name):\n",
    "    dfs = [pd.read_json(f) for f in flist]\n",
    "    df = pd.concat((idf.set_index(idx_name) for idf in dfs), \n",
    "                   axis=1, join='inner').reset_index()\n",
    "    return df\n",
    "\n",
    "#################################\n",
    "### Feature Engineering Funcs ###\n",
    "#################################\n",
    "\n",
    "# For time based columns\n",
    "def transformation(column):\n",
    "    max_value = column.max()\n",
    "    sin_values = [math.sin((2*pi*x)/max_value) for x in list(column)]\n",
    "    cos_values = [math.cos((2*pi*x)/max_value) for x in list(column)]\n",
    "    return sin_values, cos_values\n",
    "\n",
    "###################\n",
    "### Stats Funcs ###\n",
    "###################\n",
    "\n",
    "# Verify column skew for normalization requirement\n",
    "def skewness_test(df, col_list):\n",
    "    x_var = df[col_list]\n",
    "    skew_data = pd.DataFrame()\n",
    "    skew_data['features'] = x_var.columns\n",
    "    skew_data['skew'] = x_var.skew().values\n",
    "    return skew_data\n",
    "\n",
    "# Verify Column Vif scores for multicollinearity \n",
    "def vif_test(df, col_list):\n",
    "    x_var = df[col_list]\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data['features'] = x_var.columns\n",
    "    vif_data['vif'] = [variance_inflation_factor(x_var.values, i)\\\n",
    "                      for i in range(len(x_var.columns))]\n",
    "    return vif_data\n",
    "\n",
    "########################################\n",
    "### Model Reporting & Plotting Funcs ###\n",
    "########################################\n",
    "\n",
    "# Nicely Formatted Confusion Matrix\n",
    "def formatted_cf(yt, yp, n):\n",
    "    ## Confusion Matrix source: https://medium.com/@dtuk81/confusion-matrix-visualization-fc31e3f30fea\n",
    "    cf_matrix = confusion_matrix(yt,yp)\n",
    "    \n",
    "    # Get Labels\n",
    "    xy_label = sorted(set(yt))\n",
    "\n",
    "    # CF values as string formated numbers\n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in \\\n",
    "                    cf_matrix.flatten()]\n",
    "\n",
    "    # CF values as string formated percentages \n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in \\\n",
    "                         cf_matrix.flatten()/np.sum(cf_matrix)]\n",
    "\n",
    "    # Zip Names, Counts, and Percentages together into a list\n",
    "    labels = [f\"{v1}\\n{v2}\" for v1, v2 in \\\n",
    "              zip(group_counts,group_percentages)]\n",
    "\n",
    "    # Make labels a nd array from a 0d list\n",
    "    labels = np.asarray(labels).reshape(n,n)\n",
    "    \n",
    "    # Set size of plot\n",
    "    fig, ax = plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    # Call Heat Map\n",
    "    sns.heatmap(cf_matrix, \n",
    "                annot=labels, \n",
    "                fmt=\"\", \n",
    "                cmap='Blues',\n",
    "                xticklabels=xy_label,\n",
    "                yticklabels=xy_label)\n",
    "    \n",
    "    plt.ylabel(\"True label\")\n",
    "    plt.xlabel(\"Predicted label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# Classification Report\n",
    "def model_reporting(ytest, ypred, label_list, n):\n",
    "    \n",
    "    # Relabel predicted labels with ground truth labels\n",
    "    relabel = np.choose(ypred, label_list).astype(np.int64)\n",
    "    \n",
    "    print(\"\\n\\n\", classification_report(ytest, relabel), \"\\n\\n\")\n",
    "    \n",
    "    formatted_cf(ytest, relabel, n)\n",
    "    \n",
    "###################################\n",
    "### Pipeline & Gridsearch Funcs ###\n",
    "###################################\n",
    "\n",
    "# Pipeline model with Gridsearch\n",
    "def pipe_grid_model(xtrain, ytrain,\n",
    "                    numeric_features, categorical_features,\n",
    "                    estimator='LogisticRegression'):\n",
    "    \n",
    "    # Numerical features pipeline with StandardScaler\n",
    "    numeric_transformer = Pipeline([('scaler', StandardScaler()),\n",
    "                                    ('pca', PCA())])\n",
    "    # Categorical features pipeline with OHE\n",
    "    categorical_transformer = OneHotEncoder(drop='first')\n",
    "    \n",
    "    # Combine Num and Cat feature Pipelines into preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[('num', numeric_transformer, numeric_features),\n",
    "                     ('cat', categorical_transformer, categorical_features)])\n",
    "    \n",
    "    if estimator == 'LogisticRegression':\n",
    "        # Set pipeline with Preprocessor, Regressor\n",
    "        pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('reg', LogisticRegression())])\n",
    "\n",
    "        # Parametrs grid\n",
    "        param_grid = [{'preprocessor__num__pca__n_components': np.arange(50,500,50),\n",
    "                       'reg__penalty': ['elasticnet'],\n",
    "                       'reg__solver': ['saga'],\n",
    "                       'reg__random_state': [0],\n",
    "                       'reg__l1_ratio': [0.25,0.5,0.75],\n",
    "                       'reg__fit_intercept': [True, False],\n",
    "                       'reg__max_iter': [1000,2000],\n",
    "                       'reg__C': [0.25,0.5,1,2,3,4],\n",
    "                       'reg__tol': [0.000001,0.00001,0.0001,0.001]}]\n",
    "\n",
    "    if estimator == 'XGBClassifier':\n",
    "        # Set pipeline with Scaler, Regressor\n",
    "        pipe = Pipeline([('preprocessor', preprocessor),\n",
    "                         ('xgb', XGBClassifier())])\n",
    "\n",
    "        # Parametrs grid\n",
    "        param_grid = [{'preprocessor__num__pca__n_components': np.arange(50,500,50),\n",
    "                       'xgb__objective': ['binary:logistic'],\n",
    "                       'xgb__booster': ['gblinear', 'gbtree'],\n",
    "                       'xgb__eval_metric': ['error'],\n",
    "                       'xgb__feature_selector': ['shuffle', 'cyclic'],\n",
    "                       'xgb__max_depth': [3, 4, 5, 7],\n",
    "                       'xgb__learning_rate': [0.1, 0.01, 0.05],\n",
    "                       'xgb__gamma': [0, 0.25, 1],\n",
    "                       'xgb__reg_lambda': [0, 1, 10],\n",
    "                       'xgb__scale_pos_weight': [1, 3, 5],\n",
    "                       'xgb__subsample': [0.5, 0.7, 0.9],\n",
    "                       'xgb__colsample_bytree': [0.5, 0.7, 0.9],\n",
    "                       'xgb__n_estimators': np.arange(50,400,50),\n",
    "                       'xgb__num_round': [500, 1000],\n",
    "                       'xgb__random_state': [0]}]\n",
    "\n",
    "    # Call grid function with parameters and pipeline\n",
    "    grid = HalvingRandomSearchCV(pipe, param_grid, cv=10)\n",
    "    grid.fit(xtrain, ytrain)\n",
    "        \n",
    "    # Review best params\n",
    "    print(grid.best_params_)\n",
    "    \n",
    "    # Create model\n",
    "    model = grid.best_estimator_\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6479a65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################\n",
    "### LOAD DATA ###\n",
    "#################\n",
    "\n",
    "data_path = '../data'\n",
    "\n",
    "# Load Statistics\n",
    "stats_df = pandas_loader(zlist_files(data_path, 'nfl_data_2002_2021.zip', 'stats'), 'id')\n",
    "#stats_df.head(10)\n",
    "\n",
    "# Load Record\n",
    "record_df = pandas_loader(zlist_files(data_path, 'nfl_data_2002_2021.zip', 'record'), 'id')\n",
    "#record_df.head(10)\n",
    "\n",
    "# Load matches\n",
    "matches_df = pd.read_json(zlist_files(data_path, 'nfl_data_2002_2021.zip', 'matches')[0])\n",
    "#matches_df.head(10)\n",
    "\n",
    "# Load teams\n",
    "teams_df = pd.read_json(zlist_files(data_path, 'nfl_data_2002_2021.zip', 'teams')[0])\n",
    "#teams_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb159ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### JOIN DATA & CLEAN ###\n",
    "#########################\n",
    "\n",
    "# Remove Duplicate columns from Stats and Records df\n",
    "stats_df = stats_df.loc[:,~stats_df.columns.duplicated()]\n",
    "record_df = record_df.loc[:,~record_df.columns.duplicated()]\n",
    "\n",
    "# Merge Stats and Record dfs\n",
    "merged_df = stats_df.merge(record_df, how='left', on=['id'])\n",
    "#merged_df.head(10)\n",
    "\n",
    "# Merge Merged df with Teams df\n",
    "remerge_df = merged_df.merge(teams_df, how='left', left_on='team_id_x', \n",
    "                             right_on='id')\n",
    "#remerge_df.head(35)\n",
    "\n",
    "# Merge Remerged df to Matches df\n",
    "nfl_df = matches_df.merge(remerge_df, left_on=['season', 'home_team'], \n",
    "                          right_on=['season_x','team_id_x'])\\\n",
    "                   .merge(remerge_df, left_on=['season', 'away_team'], \n",
    "                          right_on=['season_x','team_id_x'],\n",
    "                          suffixes=('_home', '_away'))\n",
    "\n",
    "# Convert date_time column to datetime object\n",
    "nfl_df['date_time'] = pd.to_datetime(nfl_df['date_time'], utc=True)\n",
    "# Sort NFL df by date_time\n",
    "nfl_df = nfl_df.sort_values(['date_time'])\n",
    "\n",
    "# Drop redundant columns like id_x/id_y, etc\n",
    "drop_cols = [col for col in nfl_df.columns if '_x_' in col or '_y_' in col]\n",
    "nfl_df = nfl_df.drop(drop_cols, axis=1)\n",
    "\n",
    "# Drop Rank and PG columns\n",
    "drop_rankpg_cols = [col for col in nfl_df.columns\\\n",
    "                    if 'rank' in col or 'pg' in col]\n",
    "nfl_df = nfl_df.drop(drop_rankpg_cols, axis=1)\n",
    "\n",
    "# Drop stats columns with 999 values in it\n",
    "drop_999_cols = [col for col in nfl_df.columns[nfl_df.isin([999]).any()]\\\n",
    "                   if 'stat' in col]\n",
    "nfl_df = nfl_df.drop(drop_999_cols, axis=1)\n",
    "\n",
    "# Drop stats and record columns with only 0 values\n",
    "drop_0_cols = [col for col, is_zero in ((nfl_df == 0).sum() == nfl_df.shape[0])\\\n",
    "               .items() if is_zero and ('stat' in col or 'record' in col)]\n",
    "nfl_df = nfl_df.drop(drop_0_cols, axis=1)\n",
    "\n",
    "# Replace 999 values in matches info\n",
    "replace_999_cols = ['home_team_win', 'home_team_score', \n",
    "                    'away_team_win', 'away_team_score']\n",
    "nfl_df[replace_999_cols] = nfl_df[replace_999_cols].replace(999,0)\n",
    "\n",
    "# Drop Abbreviation team name col\n",
    "drop_abb_col = [col for col in nfl_df.columns if 'abbreviation' in col]\n",
    "nfl_df = nfl_df.drop(drop_abb_col, axis=1)\n",
    "\n",
    "# Replace remaining NaNs with 0\n",
    "nfl_df = nfl_df.fillna(0)\n",
    "\n",
    "nfl_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01d803",
   "metadata": {},
   "outputs": [],
   "source": [
    "#########################\n",
    "### DATA VERIFICATION ###\n",
    "#########################\n",
    "\n",
    "# Float and Int cols with Stats and Record\n",
    "verification_cols = [col for col in list(nfl_df.select_dtypes\\\n",
    "                                         (include=['float64', 'int64']).columns)\\\n",
    "                    if 'stat' in col or 'record' in col]\n",
    "\n",
    "# Skewness of the data for int and float columns\n",
    "skew_data = skewness_test(nfl_df, verification_cols)\n",
    "print(skew_data[(skew_data['skew'] > 0.5) | (skew_data['skew'] < -0.5)]\\\n",
    "      .sort_values('skew', ascending=False))\n",
    "skew_data['skew'].hist(bins='auto')\n",
    "plt.show()\n",
    "        \n",
    "# View Columns with high multicollinearity\n",
    "vif_data = vif_test(nfl_df, verification_cols)\n",
    "print(vif_data[vif_data['vif'] > 1].sort_values('vif', ascending=False))\n",
    "vif_data[vif_data['vif'] < 1000]['vif'].hist(bins='auto')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03af1b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### FEATURE ENGINEERING ###\n",
    "###########################\n",
    "\n",
    "# Date_time to Month, Day of Week, Time of Day as ints\n",
    "nfl_df['month'] = nfl_df['date_time'].dt.month.astype('int64')\n",
    "nfl_df['day_week'] = nfl_df['date_time'].dt.dayofweek.astype('int64')\n",
    "nfl_df['time_day'] = nfl_df['date_time'].dt.hour.astype('int64')\n",
    "\n",
    "# Calculate Cosine and Sine for new dates\n",
    "for col in ['month', 'day_week', 'time_day']:\n",
    "    time_sine, time_cos = transformation(nfl_df[col])\n",
    "    nfl_df[col[0:3]+'_sine'] = time_sine\n",
    "    nfl_df[col[0:3]+'_cos'] = time_cos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e849e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "### X & y SPLIT ###\n",
    "###################\n",
    "\n",
    "# X cols list\n",
    "keep_cols = ['stat', 'record', 'sine', 'cos',\n",
    "             'division', 'conference', 'team_name', 'location']\n",
    "\n",
    "remove_cols = ['team_win', 'team_Score', 'id', 'date_time',\n",
    "               'month', 'day_week', 'time_day']\n",
    "\n",
    "X_cols =  [col for col in list(nfl_df.columns)\\\n",
    "                    if any(kc in col for kc in keep_cols)\\\n",
    "           and any(rc not in col for rc in remove_cols)]\n",
    "\n",
    "## Split X and y into Train and Test\n",
    "# X,y Train\n",
    "X_train = nfl_df[~nfl_df['season'].isin([2021])][X_cols]\n",
    "y_train = nfl_df[~nfl_df['season'].isin([2021])]['home_team_win']\n",
    "# X,y Test\n",
    "X_test = nfl_df[nfl_df['season'].isin([2021])][X_cols]\n",
    "y_test = nfl_df[nfl_df['season'].isin([2021])]['home_team_win']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1c9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "### MODELLING: LOGISTIC REGRESSION ###\n",
    "######################################\n",
    "\n",
    "# Numerical cols to StandardScaler\n",
    "num_cols = [col for col in list(X_train.select_dtypes\\\n",
    "                                         (include=['float64', 'int64']).columns)\\\n",
    "                    if 'stat' in col or 'record' in col]\n",
    "\n",
    "# Categorical cols to OHE\n",
    "cat_cols = ['division_home', 'conference_home', \n",
    "            'location_home', 'team_name_home',\n",
    "            'division_away', 'conference_away', \n",
    "            'location_away', 'team_name_away']\n",
    "\n",
    "\n",
    "logreg_model = pipe_grid_model(X_train, y_train,\n",
    "                               num_cols, cat_cols,\n",
    "                               estimator='LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9862ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "### SAVE MODELS ###\n",
    "###################\n",
    "\n",
    "# Model path\n",
    "model_path = '../model'\n",
    "\n",
    "# file names\n",
    "log_modelName = 'winprob_logreg_2002_2020.joblib'\n",
    "\n",
    "# Save files to model folder\n",
    "dump(logreg_model, join(model_path, log_modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2719fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "### 2021 PREDICTIONS, TABLES, & PLOTTING ###\n",
    "############################################\n",
    "\n",
    "## 2021 DATA \n",
    "\n",
    "# Fit Model\n",
    "logreg_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "pred_label = logreg_model.predict(X_test)\n",
    "\n",
    "# Probabilities\n",
    "prob = logreg_model.predict_proba(X_test)\n",
    "\n",
    "# Create confusion matrix and classification report\n",
    "model_reporting(y_test, pred_label, list(np.unique(y_test)), 2)\n",
    "\n",
    "# Weekly results Table\n",
    "nfl_df2021 = nfl_df[nfl_df['season'] == 2021][['team_name_home',\n",
    "                                               'team_name_away',\n",
    "                                               'week',\n",
    "                                               'home_team_win']]\n",
    "\n",
    "# Change column names\n",
    "nfl_df2021 = nfl_df2021.rename(columns={'team_name_home':'home_team',\n",
    "                                        'team_name_away':'away_team'})\n",
    "\n",
    "# Add probability column to df\n",
    "nfl_df2021['home_team_win_probability'] = prob[:,1]\n",
    "# Add predicted labels\n",
    "nfl_df2021['predicted_winner'] = pred_label\n",
    "\n",
    "# Map actual winner name to column\n",
    "nfl_df2021['actual_winner'] = nfl_df2021.apply(lambda x: x.home_team if x.home_team_win == 1 else x.away_team, axis=1)\n",
    "# Map predicted winner name to column\n",
    "nfl_df2021['predicted_winner'] = nfl_df2021.apply(lambda x: x.home_team if x.predicted_winner == 1 else x.away_team, axis=1)\n",
    "# Map win probability\n",
    "nfl_df2021['win_probability'] = nfl_df2021.apply(lambda x: x.home_team_win_probability if x.predicted_winner == x.home_team else 1 - x.home_team_win_probability, axis=1)\n",
    "# Map correct predicition\n",
    "nfl_df2021['correct_prediction'] = (nfl_df2021['predicted_winner'] == nfl_df2021['actual_winner']).astype(int)\n",
    "\n",
    "# Drop columns\n",
    "nfl_df2021 = nfl_df2021.drop(columns=['home_team_win_probability', 'home_team_win'])\n",
    "# Show top predictions\n",
    "print(nfl_df2021.sort_values(by='win_probability', ascending=False).reset_index(drop=True).head(10))\n",
    "\n",
    "# Show per week scores\n",
    "logreg_correct = nfl_df2021.loc[nfl_df2021['correct_prediction'] == 1].groupby('week')['correct_prediction'].sum()\n",
    "# Get number of games\n",
    "num_games = nfl_df2021.groupby('week')['correct_prediction'].size()\n",
    "# Divide correct games by\n",
    "logreg_results = logreg_correct / num_games\n",
    "\n",
    "print(logreg_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7497ca6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################\n",
    "### MODELLING: XGB CLASSIFICATION ###\n",
    "#####################################\n",
    "\n",
    "# Numerical cols to StandardScaler\n",
    "num_cols = [col for col in list(X_train.select_dtypes\\\n",
    "                                         (include=['float64', 'int64']).columns)\\\n",
    "                    if 'stat' in col or 'record' in col]\n",
    "\n",
    "# Categorical cols to OHE\n",
    "cat_cols = ['division_home', 'conference_home', \n",
    "            'location_home', 'team_name_home',\n",
    "            'division_away', 'conference_away', \n",
    "            'location_away', 'team_name_away']\n",
    "\n",
    "\n",
    "xgb_model = pipe_grid_model(X_train, y_train,\n",
    "                            num_cols, cat_cols,\n",
    "                            estimator='XGBClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ea6d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################\n",
    "### SAVE MODELS ###\n",
    "###################\n",
    "\n",
    "# Model path\n",
    "model_path = '../model'\n",
    "\n",
    "# file names\n",
    "xgb_modelName = 'winprob_xgb_2002_2020.joblib'\n",
    "\n",
    "# Save files to model folder\n",
    "dump(xgb_model, join(model_path, xgb_modelName))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "123e68f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "### 2021 PREDICTIONS, TABLES, & PLOTTING ###\n",
    "############################################\n",
    "\n",
    "## 2021 DATA \n",
    "\n",
    "# Fit Model\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict labels\n",
    "pred_label = xgb_model.predict(X_test)\n",
    "\n",
    "# Probabilities\n",
    "prob = xgb_model.predict_proba(X_test)\n",
    "\n",
    "# Create confusion matrix and classification report\n",
    "model_reporting(y_test, pred_label, list(np.unique(y_test)), 2)\n",
    "\n",
    "# Weekly results Table\n",
    "nfl_df2021 = nfl_df[nfl_df['season'] == 2021][['team_name_home',\n",
    "                                               'team_name_away',\n",
    "                                               'week',\n",
    "                                               'home_team_win']]\n",
    "\n",
    "# Change column names\n",
    "nfl_df2021 = nfl_df2021.rename(columns={'team_name_home':'home_team',\n",
    "                                        'team_name_away':'away_team'})\n",
    "\n",
    "# Add probability column to df\n",
    "nfl_df2021['home_team_win_probability'] = prob[:,1]\n",
    "# Add predicted labels\n",
    "nfl_df2021['predicted_winner'] = pred_label\n",
    "\n",
    "# Map actual winner name to column\n",
    "nfl_df2021['actual_winner'] = nfl_df2021.apply(lambda x: x.home_team if x.home_team_win == 1 else x.away_team, axis=1)\n",
    "# Map predicted winner name to column\n",
    "nfl_df2021['predicted_winner'] = nfl_df2021.apply(lambda x: x.home_team if x.predicted_winner == 1 else x.away_team, axis=1)\n",
    "# Map win probability\n",
    "nfl_df2021['win_probability'] = nfl_df2021.apply(lambda x: x.home_team_win_probability if x.predicted_winner == x.home_team else 1 - x.home_team_win_probability, axis=1)\n",
    "# Map correct predicition\n",
    "nfl_df2021['correct_prediction'] = (nfl_df2021['predicted_winner'] == nfl_df2021['actual_winner']).astype(int)\n",
    "\n",
    "# Drop columns\n",
    "nfl_df2021 = nfl_df2021.drop(columns=['home_team_win_probability', 'home_team_win'])\n",
    "# Show top predictions\n",
    "print(nfl_df2021.sort_values(by='win_probability', ascending=False).reset_index(drop=True).head(10))\n",
    "\n",
    "# Show per week scores\n",
    "xgb_correct = nfl_df2021.loc[nfl_df2021['correct_prediction'] == 1].groupby('week')['correct_prediction'].sum()\n",
    "# Get number of games\n",
    "num_games = nfl_df2021.groupby('week')['correct_prediction'].size()\n",
    "# Divide correct games by\n",
    "xgb_results = xgb_correct / num_games\n",
    "\n",
    "print(xgb_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723b3a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "### LOGISTIC REGRESSION VS XGBOOST ###\n",
    "######################################\n",
    "\n",
    "results_comp = pd.DataFrame()\n",
    "results_comp.index = xgb_results.index[0:13]\n",
    "results_comp['xgb'] = xgb_results.values[0:13]\n",
    "results_comp['logreg'] = logreg_results.values[0:13]\n",
    "results_comp['dif'] = xgb_results.values[0:13] - logreg_results.values[0:13]\n",
    "results_comp['best_week'] = np.where(results_comp['xgb'] > results_comp['logreg'], \n",
    "                                     'xgb', 'logreg')\n",
    "results_comp['best_week'] = np.where(results_comp['xgb'] == results_comp['logreg'], \n",
    "                                     'tie',results_comp['best_week'])\n",
    "results_comp['best_week_val'] = np.where(results_comp['xgb'] > results_comp['logreg'], \n",
    "                                     results_comp['xgb'], results_comp['logreg'])\n",
    "results_comp.loc['mean'] = results_comp.mean()\n",
    "results_comp['best_week'].loc['mean'] = max(results_comp['best_week'].value_counts())\n",
    "results_comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1466e86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### WEEK 14 PREDICTIONS ###\n",
    "###########################\n",
    "\n",
    "# Week 14\n",
    "table_cols = ['home_team','away_team', 'predicted_winner','win_probability']\n",
    "week14_df = pd.DataFrame()\n",
    "week14_df[table_cols] = nfl_df2021[nfl_df2021['week']==14][table_cols]\n",
    "\n",
    "week14_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fdd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### WEEK 15 PREDICTIONS ###\n",
    "###########################\n",
    "\n",
    "# Week 15\n",
    "table_cols = ['home_team','away_team', 'predicted_winner','win_probability']\n",
    "week15_df = pd.DataFrame()\n",
    "week15_df[table_cols] = nfl_df2021[nfl_df2021['week']==15][table_cols]\n",
    "\n",
    "week15_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a313e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### WEEK 16 PREDICTIONS ###\n",
    "###########################\n",
    "\n",
    "# Week 16\n",
    "table_cols = ['home_team','away_team', 'predicted_winner','win_probability']\n",
    "week16_df = pd.DataFrame()\n",
    "week16_df[table_cols] = nfl_df2021[nfl_df2021['week']==16][table_cols]\n",
    "\n",
    "week16_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ddc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### WEEK 17 PREDICTIONS ###\n",
    "###########################\n",
    "\n",
    "# Week 17\n",
    "table_cols = ['home_team','away_team', 'predicted_winner','win_probability']\n",
    "week17_df = pd.DataFrame()\n",
    "week17_df[table_cols] = nfl_df2021[nfl_df2021['week']==17][table_cols]\n",
    "\n",
    "week17_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9d3aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "### WEEK 18 PREDICTIONS ###\n",
    "###########################\n",
    "\n",
    "# Week 18\n",
    "table_cols = ['home_team','away_team', 'predicted_winner','win_probability']\n",
    "week18_df = pd.DataFrame()\n",
    "week18_df[table_cols] = nfl_df2021[nfl_df2021['week']==18][table_cols]\n",
    "\n",
    "week18_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a02b4c19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
